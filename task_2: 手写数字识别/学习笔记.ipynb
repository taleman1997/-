{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手写数字识别任务\n",
    "\n",
    "\n",
    "在处理如 **图1** 所示的手写邮政编码的简单图像分类任务时，可以使用基于MNIST数据集的手写数字识别模型。MNIST是深度学习领域标准、易用的成熟数据集，包含60000条训练样本和10000条测试样本。\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/04ab1f9d699e40659a4b69ee069a5136a15cb04bb9d848c2be536da68a8abe5e\" width=\"600\" hegiht=\"40\" ></center>\n",
    "<center><br>图1：手写数字识别任务示意图</br></center>\n",
    "\n",
    "* 任务输入：一系列手写数字图片，其中每张图片都是28x28的像素矩阵。\n",
    "* 任务输出：经过了大小归一化和居中处理，输出对应的0~9的数字标签。\n",
    "\n",
    "\n",
    "## 构建手写数字识别的神经网络模型\n",
    "\n",
    "使用飞桨完成手写数字识别模型任务的代码结构如 **图2** 所示，与使用飞桨完成房价预测模型任务的流程一致，下面的章节中我们将详细介绍每个步骤的具体实现方法和优化思路。\n",
    "<br></br>\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/38b467ff3b6e4705b9b4d34c6b13431073e449640ef847f396923475b11c913b\" width=\"800\" hegiht=\"\" ></center>\n",
    "<center><br>图2：使用飞桨框架构建神经网络过程</br></center>\n",
    "<br></br>\n",
    "\n",
    "\n",
    "## 思考过程\n",
    "\n",
    "在本教程中，我们采用了“横纵式”教学法进行深度学习建模介绍，如 **图4** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/82a84e5e3d054c858c65cf5f8988394950e6945c1a5c4d378ce9ead92c0fb91d\"  width=\"800\" ></center>\n",
    "<center><br>图4：创新性的“横纵式”教学法<br/></center>\n",
    "<br><br/>\n",
    "\n",
    "在“横纵式”教学法中，纵向概要介绍模型的基本代码结构和极简实现方案。横向深入探讨构建模型的每个环节中，更优但相对复杂的实现方案。例如在模型设计环节，除了在极简版本使用的单层神经网络（与房价预测模型一样）外，还可以尝试更复杂的网络结构，如多层神经网络、加入非线性的激活函数，甚至专门针对视觉任务优化的卷积神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在开始之前，加载飞桨和相关数据处理的库\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph.nn import Linear\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始\n",
    "\n",
    "## 数据处理：\n",
    "\n",
    "在实际应用中，保存到本地的数据存储格式多种多样，如MNIST数据集以json格式存储在本地，其数据存储结构如 **图2** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/7d278024d7ac4d6689fdbe0aa1729181699444730e3941d386a55a1ff8ab4276\" width=\"500\" hegiht=\"\" ></center>\n",
    "<center><br>图2：MNIST数据集的存储结构</br></center>\n",
    "<br></br>\n",
    "\n",
    "**data**包含三个元素的列表：**train_set**、**val_set**、 **test_set**。\n",
    "\n",
    "* **train_set（训练集）**：包含50000条手写数字图片和对应的标签，用于确定模型参数。\n",
    "* **val_set（验证集）**：包含10000条手写数字图片和对应的标签，用于调节模型超参数（如多个网络结构、正则化权重的最优选择）。\n",
    "* **test_set（测试集）**：包含10000条手写数字图片和对应的标签，用于估计应用效果（没有在模型中应用过的数据，更贴近模型在真实场景应用的效果）。\n",
    "\n",
    "**train_set**包含两个元素的列表：**train_images**、**train_labels**。\n",
    "\n",
    "* **train_images**：[50000, 784]的二维列表，包含50000张图片。每张图片用一个长度为784的向量表示，内容是28\\*28尺寸的像素灰度值（黑白图片）。\n",
    "* **train_labels**：[50000, ]的列表，表示这些图片对应的分类标签，即0-9之间的一个数字。\n",
    "\n",
    "在本地目录下读取文件名称为`mnist.json.gz`的MNIST数据，并拆分成训练集、验证集和测试集，实现方法如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mnist dataset from mnist.json.gz ......\n",
      "mnist dataset load done\n",
      "训练数据集数量:  50000\n",
      "验证数据集数量:  10000\n",
      "测试数据集数量:  10000\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# 声明数据集文件位置\n",
    "datafile = 'mnist.json.gz'\n",
    "print('loading mnist dataset from {} ......'.format(datafile))\n",
    "# 加载json数据文件\n",
    "data = json.load(gzip.open(datafile))\n",
    "print('mnist dataset load done')\n",
    "# 读取到的数据区分训练集，验证集，测试集\n",
    "train_set, val_set, eval_set = data\n",
    "\n",
    "# 数据集相关参数，图片高度IMG_ROWS, 图片宽度IMG_COLS\n",
    "IMG_ROWS = 28\n",
    "IMG_COLS = 28\n",
    "\n",
    "# 打印数据信息\n",
    "imgs, labels = train_set[0], train_set[1]\n",
    "print(\"训练数据集数量: \", len(imgs))\n",
    "\n",
    "# 观察验证集数量\n",
    "imgs, labels = val_set[0], val_set[1]\n",
    "print(\"验证数据集数量: \", len(imgs))\n",
    "\n",
    "# 观察测试集数量\n",
    "imgs, labels = val= eval_set[0], eval_set[1]\n",
    "print(\"测试数据集数量: \", len(imgs))\n",
    "\n",
    "print(type(train_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练样本乱序、生成批次数据\n",
    "\n",
    "* **训练样本乱序：** 先将样本按顺序进行编号，建立ID集合index_list。然后将index_list乱序，最后按乱序后的顺序读取数据。\n",
    "\n",
    "------\n",
    "**说明：**\n",
    "\n",
    "通过大量实验发现，模型对最后出现的数据印象更加深刻。训练数据导入后，越接近模型训练结束，最后几个批次数据对模型参数的影响越大。为了避免模型记忆影响训练效果，需要进行样本乱序操作。\n",
    "\n",
    "------\n",
    "* **生成批次数据：** 先设置合理的batch_size，再将数据转变成符合模型输入要求的np.array格式返回。同时，在返回数据时将Python生成器设置为``yield``模式，以减少内存占用。\n",
    "\n",
    "在执行如上两个操作之前，需要先将数据处理代码封装成`load_data`函数，方便后续调用。`load_data`有三种模型：``train``、``valid``、``eval``，分为对应返回的数据是训练集、验证集、测试集。`load_data` 函数代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(mode):\n",
    "    datafile = 'mnist.json.gz'\n",
    "    print('loading mnist dataset from {} ......'.format(datafile))\n",
    "    # 加载json数据文件\n",
    "    data = json.load(gzip.open(datafile))\n",
    "    print('mnist dataset load done')\n",
    "   \n",
    "    # 读取到的数据区分训练集，验证集，测试集\n",
    "    train_set, val_set, eval_set = data\n",
    "    if mode=='train':\n",
    "        # 获得训练数据集\n",
    "        imgs, labels = train_set[0], train_set[1]\n",
    "    elif mode=='valid':\n",
    "        # 获得验证数据集\n",
    "        imgs, labels = val_set[0], val_set[1]\n",
    "    elif mode=='eval':\n",
    "        # 获得测试数据集\n",
    "        imgs, labels = eval_set[0], eval_set[1]\n",
    "    else:\n",
    "        raise Exception(\"mode can only be one of ['train', 'valid', 'eval']\")\n",
    "    print(\"训练数据集数量: \", len(imgs))\n",
    "    \n",
    "    # 校验数据\n",
    "    imgs_length = len(imgs)\n",
    "\n",
    "    assert len(imgs) == len(labels), \\\n",
    "          \"length of train_imgs({}) should be the same as train_labels({})\".format(len(imgs), len(label))\n",
    "    \n",
    "    # 获得数据集长度\n",
    "    imgs_length = len(imgs)\n",
    "    \n",
    "    # 定义数据集每个数据的序号，根据序号读取数据\n",
    "    index_list = list(range(imgs_length))\n",
    "    # 读入数据时用到的批次大小\n",
    "    BATCHSIZE = 100\n",
    "    \n",
    "    # 定义数据生成器： 注意当要求改动时 一下代码或需要改动\n",
    "    def data_generator():\n",
    "        if mode == 'train':\n",
    "            # 训练模式下打乱数据\n",
    "            random.shuffle(index_list)\n",
    "        imgs_list = []\n",
    "        labels_list = []\n",
    "        for i in index_list:\n",
    "            # 将数据处理成希望的格式，比如类型为float32，shape为[1, 28, 28]\n",
    "            img = np.reshape(imgs[i], [1, IMG_ROWS, IMG_COLS]).astype('float32')\n",
    "            label = np.reshape(labels[i], [1]).astype('float32')\n",
    "            imgs_list.append(img) \n",
    "            labels_list.append(label)\n",
    "            if len(imgs_list) == BATCHSIZE:\n",
    "                # 获得一个batchsize的数据，并返回\n",
    "                yield np.array(imgs_list), np.array(labels_list)\n",
    "                # 清空数据读取列表\n",
    "                imgs_list = []\n",
    "                labels_list = []\n",
    "    \n",
    "        # 如果剩余数据的数目小于BATCHSIZE，\n",
    "        # 则剩余数据一起构成一个大小为len(imgs_list)的mini-batch\n",
    "        if len(imgs_list) > 0:\n",
    "            yield np.array(imgs_list), np.array(labels_list)\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络设计\n",
    "\n",
    "手写数字识别的输入是28 × 28的像素值，输出是0-9的数字标签。而线性回归模型无法捕捉二维图像数据中蕴含的复杂信息，如 **图1** 所示。无论是牛顿第二定律任务，还是房价预测任务，输入特征和输出预测值之间的关系均可以使用“直线”刻画（使用线性方程来表达）。但手写数字识别任务的输入像素和输出数字标签之间的关系显然不是线性的，甚至这个关系复杂到我们靠人脑难以直观理解的程度。  \n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/4479e3a4b7a0401393c6feb0484dffbe3f2ff3af17b445ebbbee88c10fd7c1dc\" width=\"600\" hegiht=\"\" ></center>\n",
    "<center><br>图1：数字识别任务的输入和输出不是线性关系 </br></center>\n",
    "<br></br>\n",
    "\n",
    "因此，我们需要尝试使用其他更复杂、更强大的网络来构建手写数字识别任务，并观察一下训练效果。将“横纵式”教学法从横向展开，如 **图2** 所示，本节主要介绍两种常见的网络结构：经典的多层全连接神经网络和卷积神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 经典的全连接神经网络\n",
    "\n",
    "\n",
    "经典的全连接神经网络来包含四层网络：输入层、两个隐含层和输出层，将手写数字识别任务通过全连接神经网络表示，如 **图3** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/2173259df0704335b230ec158be0427677b9c77fd42348a28f2f8adf1ac1c706\" width=\"600\" hegiht=\"\" ></center>\n",
    "<center><br>图3：手写数字识别任务的全连接神经网络结构</br></center>\n",
    "<br></br>\n",
    "\n",
    "* 输入层：将数据输入给神经网络。在该任务中，输入层的尺度为28×28的像素值。\n",
    "* 隐含层：增加网络深度和复杂度，隐含层的节点数是可以调整的，节点数越多，神经网络表示能力越强，参数量也会增加。在该任务中，中间的两个隐含层为10×10的结构，通常隐含层会比输入层的尺寸小，以便对关键信息做抽象，激活函数使用常见的`sigmoid`函数。\n",
    "* 输出层：输出网络计算结果，输出层的节点数是固定的。如果是回归问题，节点数量为需要回归的数字数量；如果是分类问题，则是分类标签的数量。在该任务中，模型的输出是回归一个数字，输出层的尺寸为1。\n",
    "\n",
    "------\n",
    "**说明：**\n",
    "\n",
    "隐含层引入非线性激活函数sigmoid是为了增加神经网络的非线性能力。\n",
    "\n",
    "举例来说，如果一个神经网络采用线性变换，有四个输入$x_1$~$x_4$，一个输出$y$。假设第一层的变换是$z_1=x_1-x_2$和$z_2=x_3+x_4$，第二层的变换是$y=z_1+z_2$，则将两层的变换展开后得到$y=x_1-x_2+x_3+x_4$。也就是说，无论中间累积了多少层线性变换，原始输入和最终输出之间依然是线性关系。\n",
    " \n",
    "------\n",
    "\n",
    "`Sigmoid`是早期神经网络模型中常见的非线性变换函数，通过如下代码，绘制出`Sigmoid`的函数曲线。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对手写数字识别的任务，网络层的设计如下：\n",
    "\n",
    "* 输入层的尺度为28×28，但批次计算的时候会统一加1个维度（大小为batchsize）。\n",
    "* 中间的两个隐含层为10×10的结构，激活函数使用常见的`sigmoid`函数。\n",
    "* 与房价预测模型一样，模型的输出是回归一个数字，输出层的尺寸设置成1。\n",
    "\n",
    "下述代码为经典全连接神经网络的实现。完成网络结构定义后，即可训练神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_0(fluid.dygraph.Layer):\n",
    "    def __init__(self):\n",
    "        super(MNIST, self).__init__()\n",
    "        # 定义两层全连接隐含层，输出维度是10，激活函数为sigmoid\n",
    "        self.fc1 = Linear(input_dim=784, output_dim=10, act='sigmoid') # 隐含层节点为10，可根据任务调整\n",
    "        self.fc2 = Linear(input_dim=10, output_dim=10, act='sigmoid')\n",
    "        # 定义一层全连接输出层，输出维度是1，不使用激活函数\n",
    "        self.fc3 = Linear(input_dim=10, output_dim=1, act=None)\n",
    "    \n",
    "    # 定义网络的前向计算\n",
    "    def forward(self, inputs, label=None):\n",
    "        inputs = fluid.layers.reshape(inputs, [inputs.shape[0], 784])\n",
    "        outputs1 = self.fc1(inputs)\n",
    "        outputs2 = self.fc2(outputs1)\n",
    "        outputs_final = self.fc3(outputs2)\n",
    "        return outputs_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络\n",
    "\n",
    "虽然使用经典的全连接神经网络可以提升一定的准确率，但对于计算机视觉问题，效果最好的模型仍然是卷积神经网络。卷积神经网络针对视觉问题的特点进行了网络结构优化，更适合处理视觉问题。\n",
    "\n",
    "卷积神经网络由多个卷积层和池化层组成，如 **图4** 所示。卷积层负责对输入进行扫描以生成更抽象的特征表示，池化层对这些特征表示进行过滤，保留最关键的特征信息。\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/91f3755dfd47461aa04567e73474a3ca56107402feb841a592ddaa7dfcbc67c2\" width=\"800\" hegiht=\"\" ></center>\n",
    "\n",
    "<center><br>图4：在处理计算机视觉任务中大放异彩的卷积神经网络</br></center>\n",
    "<br></br>\n",
    "\n",
    "\n",
    "-------\n",
    "**说明：**\n",
    "\n",
    "本节只简单介绍用卷积神经网络实现手写数字识别任务，以及它带来的效果提升。读者可以先将卷积神经网络简单的理解成是一种比经典的全连接神经网络更强大的模型即可，更详细的原理和实现在后面的计算机视觉章节中会详细讲述。\n",
    "\n",
    "------\n",
    "\n",
    "两层卷积和池化的卷积神经网络实现如下所示。\n",
    "\n",
    "之后的示例中将使用卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多层卷积神经网络实现\n",
    "class MNIST(fluid.dygraph.Layer):\n",
    "     def __init__(self):\n",
    "         super(MNIST, self).__init__()\n",
    "         \n",
    "         # 定义卷积层，输出特征通道num_filters设置为20，卷积核的大小filter_size为5，卷积步长stride=1，padding=2\n",
    "         # 激活函数使用relu\n",
    "         self.conv1 = Conv2D(num_channels=1, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\n",
    "         # 定义池化层，池化核pool_size=2，池化步长为2，选择最大池化方式\n",
    "         self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "         # 定义卷积层，输出特征通道num_filters设置为20，卷积核的大小filter_size为5，卷积步长stride=1，padding=2\n",
    "         self.conv2 = Conv2D(num_channels=20, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\n",
    "         # 定义池化层，池化核pool_size=2，池化步长为2，选择最大池化方式\n",
    "         self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "         # 定义一层全连接层，输出维度是1，不使用激活函数\n",
    "         self.fc = Linear(input_dim=980, output_dim=1, act=None)\n",
    "         \n",
    "    # 定义网络前向计算过程，卷积后紧接着使用池化层，最后使用全连接层计算最终输出\n",
    "     def forward(self, inputs):\n",
    "         x = self.conv1(inputs)\n",
    "         x = self.pool1(x)\n",
    "         x = self.conv2(x)\n",
    "         x = self.pool2(x)\n",
    "         x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "         x = self.fc(x)\n",
    "         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "上一节我们尝试通过更复杂的模型（经典的全连接神经网络和卷积神经网络），提升手写数字识别模型训练的准确性。本节我们继续将“横纵式”教学法从横向展开，如 **图1** 所示，探讨损失函数的优化对模型训练效果的影响。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/8ed4007a16f24549affef4549ba4e2228729b94bc69c479f91c57d0cf3a8bf52\" width=\"800\" hegiht=\"\" ></center>\n",
    "<center><br>图1：“横纵式”教学法 — 损失函数优化 </br></center>\n",
    "<br></br>\n",
    "\n",
    "损失函数是模型优化的目标，用于在众多的参数取值中，识别最理想的取值。损失函数的计算在训练过程的代码中，每一轮模型训练的过程都相同，分如下三步：\n",
    "1. 先根据输入数据正向计算预测输出。\n",
    "1. 再根据预测值和真实值计算损失。\n",
    "1. 最后根据损失反向传播梯度并更新参数。\n",
    "\n",
    "## 分类任务的损失函数\n",
    "\n",
    "在之前的方案中，我们复用了房价预测模型的损失函数-均方误差。从预测效果来看，虽然损失不断下降，模型的预测值逐渐逼近真实值，但模型的最终效果不够理想。究其根本，不同的深度学习任务需要有各自适宜的损失函数。我们以房价预测和手写数字识别两个任务为例，详细剖析其中的缘由如下：\n",
    "\n",
    "1. 房价预测是回归任务，而手写数字识别是分类任务，使用均方误差作为分类任务的损失函数存在逻辑和效果上的缺欠。\n",
    "1. 房价可以是大于0的任何浮点数，而手写数字识别的输出只可能是0-9之间的10个整数，相当于一种标签。\n",
    "1. 在房价预测的案例中，由于房价本身是一个连续的实数值，因此以模型输出的数值和真实房价差距作为损失函数（loss）是符合道理的。但对于分类问题，真实结果是分类标签，而模型输出是实数值，导致以两者相减作为损失不具备物理含义。\n",
    "\n",
    "那么，什么是分类任务的合理输出呢？分类任务本质上是“某种特征组合下的分类概率”，下面以一个简单案例说明，如 **图2** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/94b47a4dfbba43ddb20e5403e9831dd5f5ee67c4fa0148f786c506eec77889b1\" width=\"600\" hegiht=\"\" ></center>\n",
    "<center><br>图2：观测数据和背后规律之间的关系 </br></center>\n",
    "<br> </br>\n",
    "\n",
    "在本案例中，医生根据肿瘤大小$x$作为肿瘤性质$y$的参考判断（判断的因素有很多，肿瘤大小只是其中之一），那么我们观测到该模型判断的结果是$x$和$y$的标签（1为恶性，0为良性）。而这个数据背后的规律是不同大小的肿瘤，属于恶性肿瘤的概率。观测数据是真实规律抽样下的结果，分类模型应该拟合这个真实规律，输出属于该分类标签的概率。\n",
    "\n",
    "## Softmax函数\n",
    "\n",
    "如果模型能输出10个标签的概率，对应真实标签的概率输出尽可能接近100%，而其他标签的概率输出尽可能接近0%，且所有输出概率之和为1。这是一种更合理的假设！与此对应，真实的标签值可以转变成一个10维度的one-hot向量，在对应数字的位置上为1，其余位置为0，比如标签“6”可以转变成[0,0,0,0,0,0,1,0,0,0]。\n",
    "\n",
    "为了实现上述思路，需要引入Softmax函数，它可以将原始输出转变成对应标签的概率，公式如下，其中$C$是标签类别个数。\n",
    "\n",
    "$$softmax(x_i) = \\frac {e^{x_i}}{\\sum_{j=0}^N{e^x_j}}, i=0, ..., C-1$$ \n",
    "\n",
    "\n",
    "从公式的形式可见，每个输出的范围均在0~1之间，且所有输出之和等于1，这是变换后可被解释成概率的基本前提。对应到代码上，我们需要在网络定义部分修改输出层：`self.fc = Linear(input_dim=10, output_dim=1, act='softmax')`，即是对全连接层的输出加一个softmax运算。\n",
    "\n",
    "**图3** 是一个三个标签的分类模型（三分类）使用的softmax输出层，从中可见原始输出的三个数字3、1、-3，经过softmax层后转变成加和为1的三个概率值0.88、0.12、0。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/ef129caf64254318821e9410bb71ab1f45fff20e4282482986081d44a1e3bcbb\" width=\"600\" hegiht=\"\" ></center>\n",
    "<center><br>图3：网络输出层为softmax函数 </br></center>\n",
    "<br></br>\n",
    "\n",
    "上文解释了为何让分类模型的输出拟合概率的原因，但为何偏偏用softmax函数完成这个职能？ 下面以二分类问题（只输出两个标签）进行探讨。\n",
    "\n",
    "对于二分类问题，使用两个输出接入softmax作为输出层，等价于使用单一输出接入Sigmoid函数。如 **图4** 所示，利用两个标签的输出概率之和为1的条件，softmax输出0.6和0.4两个标签概率，从数学上等价于输出一个标签的概率0.6。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/4dbdf378438f42b0bc6de6f11955834b7063cc6916544017b0af2ccf1f730984\" width=\"400\" hegiht=\"\" ></center>\n",
    "<center><br>图4：对于二分类问题，等价于单一输出接入Sigmoid函数 </br></center>\n",
    "<br></br>\n",
    "\n",
    "在这种情况下，只有一层的模型为$S(w^{T}x_i)$，$S$为Sigmoid函数。模型预测为1的概率为$S(w^{T}x_i)$，模型预测为0的概率为$1-S(w^{T}x_i)$。\n",
    "\n",
    "**图5** 是肿瘤大小和肿瘤性质的数据图。从图中可发现，往往尺寸越大的肿瘤几乎全部是恶性，尺寸极小的肿瘤几乎全部是良性。只有在中间区域，肿瘤的恶性概率会从0逐渐到1（绿色区域），这种数据的分布是符合多数现实问题的规律。如果我们直接线性拟合，相当于红色的直线，会发现直线的纵轴0-1的区域会拉的很长，而我们期望拟合曲线0-1的区域与真实的分类边界区域重合。那么，观察下Sigmoid的曲线趋势可以满足我们对这个问题的一切期望，它的概率变化会集中在一个边界区域，有助于模型提升边界区域的分辨率。\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/bbf5e0eda62c44bb84528dbfd8642ef901b2dc42c6f541bc8cd0b75b967dc934\" width=\"1000\" hegiht=\"\" ></center>\n",
    "<center><br>图5：使用sigmoid拟合输出可提高分类模型对边界的分辨率 </br></center>\n",
    "<br></br>\n",
    "\n",
    "这就类似于公共区域使用的带有恒温装置的热水器温度阀门，如 **图6** 所示。由于人体适应的水温在34度-42度之间，我们更期望阀门的水温条件集中在这个区域，而不是在0-100度之间线性分布。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/9d05d75c9db44d95b8cdec6fe1615e24d9a24c0ce4f64954a2a5659aaaa7437b\" width=\"400\" hegiht=\"\" ></center>\n",
    "<center><br>图6：热水器水温控制 </br></center>\n",
    "<br></br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉熵\n",
    "\n",
    "在模型输出为分类标签的概率时，直接以标签和概率做比较也不够合理，人们更习惯使用交叉熵误差作为分类问题的损失衡量。\n",
    "\n",
    "交叉熵损失函数的设计是基于最大似然思想：最大概率得到观察结果的假设是真的。如何理解呢？举个例子来说，如 **图7** 所示。有两个外形相同的盒子，甲盒中有99个白球，1个蓝球；乙盒中有99个蓝球，1个白球。一次试验取出了一个蓝球，请问这个球应该是从哪个盒子中取出的？\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/13a942e5ec7f4e91badb2f4613c6f71a00e51c8afb6a435e94a0b47cedac9515\" width=\"400\" hegiht=\"\" ></center>\n",
    "<center><br>图7：体会最大似然的思想 </br></center>\n",
    "<br></br>\n",
    "\n",
    "\n",
    "相信大家简单思考后均会得出更可能是从乙盒中取出的，因为从乙盒中取出一个蓝球的概率更高$(P(D|h))$，所以观察到一个蓝球更可能是从乙盒中取出的$(P(h|D))$。$D$是观测的数据，即蓝球白球；$h$是模型，即甲盒乙盒。这就是贝叶斯公式所表达的思想：\n",
    "\n",
    "$$P(h|D) ∝ P(h) \\cdot P(D|h)$$\n",
    "\n",
    "依据贝叶斯公式，某二分类模型“生成”$n$个训练样本的概率：\n",
    "\n",
    "$$P(x_1)\\cdot S(w^{T}x_1)\\cdot P(x_2)\\cdot(1-S(w^{T}x_2))\\cdot … \\cdot P(x_n)\\cdot S(w^{T}x_n)$$\n",
    "\n",
    "------\n",
    "**说明：**\n",
    "\n",
    "对于二分类问题，模型为$S(w^{T}x_i)$，$S$为Sigmoid函数。当$y_i$=1，概率为$S(w^{T}x_i)$；当$y_i$=0，概率为$1-S(w^{T}x_i)$。\n",
    "\n",
    "------\n",
    "\n",
    "经过公式推导，使得上述概率最大等价于最小化交叉熵，得到交叉熵的损失函数。交叉熵的公式如下：\n",
    "\n",
    "$$ L = -[\\sum_{k=1}^{n} t_k\\log y_k +(1- t_k)\\log(1-y_k)] $$\n",
    "   \n",
    "其中，$\\log$表示以$e$为底数的自然对数。$y_k$代表模型输出，$t_k$代表各个标签。$t_k$中只有正确解的标签为1，其余均为0（one-hot表示）。\n",
    "\n",
    "因此，交叉熵只计算对应着“正确解”标签的输出的自然对数。比如，假设正确标签的索引是“2”，与之对应的神经网络的输出是0.6，则交叉熵误差是$−\\log 0.6 = 0.51$；若“2”对应的输出是0.1，则交叉熵误差为$−\\log 0.1 = 2.30$。由此可见，交叉熵误差的值是由正确标签所对应的输出结果决定的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如自然对数的图形所示，当$x$等于1时，$y$为0；随着$x$向0靠近，$y$逐渐变小。因此，“正确解”标签对应的输出越大，交叉熵的值越接近0；当输出为1时，交叉熵误差为0。反之，如果“正确解”标签对应的输出越小，则交叉熵的值越大。\n",
    "\n",
    "## 交叉熵的代码实现\n",
    "\n",
    "在手写数字识别任务中，仅改动三行代码，就可以将在现有模型的损失函数替换成交叉熵（cross_entropy）。\n",
    "\n",
    "* 在读取数据部分，将标签的类型设置成`int`，体现它是一个标签而不是实数值（飞桨默认将标签处理成“int64”）。\n",
    "* 在网络定义部分，将输出层改成“输出十个标签的概率”的模式。\n",
    "* 在训练过程部分，将损失函数从均方误差换成交叉熵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在数据处理部分，需要修改标签变量Label的格式，代码如下所示。\n",
    "- 从：label = np.reshape(labels[i], [1]).astype('float32')\n",
    "- 到：label = np.reshape(labels[i], [1]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#修改标签数据的格式，从float32到int64\n",
    "import os\n",
    "import random\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "# 定义数据集读取器\n",
    "def load_data(mode='train'):\n",
    "\n",
    "    # 数据文件\n",
    "    datafile = 'mnist.json.gz'\n",
    "    print('loading mnist dataset from {} ......'.format(datafile))\n",
    "    data = json.load(gzip.open(datafile))\n",
    "    train_set, val_set, eval_set = data\n",
    "\n",
    "    # 数据集相关参数，图片高度IMG_ROWS, 图片宽度IMG_COLS\n",
    "    IMG_ROWS = 28\n",
    "    IMG_COLS = 28\n",
    "\n",
    "    if mode == 'train':\n",
    "        imgs = train_set[0]\n",
    "        labels = train_set[1]\n",
    "    elif mode == 'valid':\n",
    "        imgs = val_set[0]\n",
    "        labels = val_set[1]\n",
    "    elif mode == 'eval':\n",
    "        imgs = eval_set[0]\n",
    "        labels = eval_set[1]\n",
    "\n",
    "    imgs_length = len(imgs)\n",
    "\n",
    "    assert len(imgs) == len(labels), \\\n",
    "          \"length of train_imgs({}) should be the same as train_labels({})\".format(\n",
    "                  len(imgs), len(labels))\n",
    "\n",
    "    index_list = list(range(imgs_length))\n",
    "\n",
    "    # 读入数据时用到的batchsize\n",
    "    BATCHSIZE = 100\n",
    "\n",
    "    # 定义数据生成器\n",
    "    def data_generator():\n",
    "        if mode == 'train':\n",
    "            random.shuffle(index_list)\n",
    "        imgs_list = []\n",
    "        labels_list = []\n",
    "        for i in index_list:\n",
    "            img = np.reshape(imgs[i], [1, IMG_ROWS, IMG_COLS]).astype('float32')\n",
    "            label = np.reshape(labels[i], [1]).astype('int64')\n",
    "            imgs_list.append(img) \n",
    "            labels_list.append(label)\n",
    "            if len(imgs_list) == BATCHSIZE:\n",
    "                yield np.array(imgs_list), np.array(labels_list)\n",
    "                imgs_list = []\n",
    "                labels_list = []\n",
    "\n",
    "        # 如果剩余数据的数目小于BATCHSIZE，\n",
    "        # 则剩余数据一起构成一个大小为len(imgs_list)的mini-batch\n",
    "        if len(imgs_list) > 0:\n",
    "            yield np.array(imgs_list), np.array(labels_list)\n",
    "\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在网络定义部分，需要修改输出层结构，代码如下所示。\n",
    "- 从：self.fc = Linear(input_dim=980, output_dim=1, act=None)\n",
    "- 到：self.fc = Linear(input_dim=980, output_dim=10, act='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型结构\n",
    "class MNIST(fluid.dygraph.Layer):\n",
    "     def __init__(self):\n",
    "         super(MNIST, self).__init__()\n",
    "         \n",
    "         # 定义一个卷积层，使用relu激活函数\n",
    "         self.conv1 = Conv2D(num_channels=1, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\n",
    "         # 定义一个池化层，池化核为2，步长为2，使用最大池化方式\n",
    "         self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "         # 定义一个卷积层，使用relu激活函数\n",
    "         self.conv2 = Conv2D(num_channels=20, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\n",
    "         # 定义一个池化层，池化核为2，步长为2，使用最大池化方式\n",
    "         self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "         # 定义一个全连接层，输出节点数为10 \n",
    "         self.fc = Linear(input_dim=980, output_dim=10, act='softmax')\n",
    "    # 定义网络的前向计算过程\n",
    "     def forward(self, inputs):\n",
    "         x = self.conv1(inputs)\n",
    "         x = self.pool1(x)\n",
    "         x = self.conv2(x)\n",
    "         x = self.pool2(x)\n",
    "         x = fluid.layers.reshape(x, [x.shape[0], 980])\n",
    "         x = self.fc(x)\n",
    "         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改计算损失的函数，从均方误差（常用于回归问题）到交叉熵误差（常用于分类问题），代码如下所示。\n",
    "- 从：loss = fluid.layers.square_error_cost(predict, label)\n",
    "- 到：loss = fluid.layers.cross_entropy(predict, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#仅修改计算损失的函数，从均方误差（常用于回归问题）到交叉熵误差（常用于分类问题）\n",
    "with fluid.dygraph.guard():\n",
    "    model = MNIST()\n",
    "    model.train()\n",
    "    #调用加载数据的函数\n",
    "    train_loader = load_data('train')\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.01, parameter_list=model.parameters())\n",
    "    EPOCH_NUM = 5\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据，变得更加简洁\n",
    "            image_data, label_data = data\n",
    "            image = fluid.dygraph.to_variable(image_data)\n",
    "            label = fluid.dygraph.to_variable(label_data)\n",
    "            \n",
    "            #前向计算的过程\n",
    "            predict = model(image)\n",
    "            \n",
    "            #计算损失，使用交叉熵损失函数，取一个批次样本损失的平均值\n",
    "            loss = fluid.layers.cross_entropy(predict, label)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            \n",
    "            #每训练了200批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            optimizer.minimize(avg_loss)\n",
    "            model.clear_gradients()\n",
    "\n",
    "    #保存模型参数\n",
    "    fluid.save_dygraph(model.state_dict(), 'mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**目前，网络的基本结构已经完成，下面将介绍学习率调节对网络的影响，不同优化方式对网络的影响，如何加载正则化项，避免模型的过度拟合。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置学习率\n",
    "\n",
    "在深度学习神经网络模型中，通常使用标准的随机梯度下降算法更新参数，学习率代表参数更新幅度的大小，即步长。当学习率最优时，模型的有效容量最大，最终能达到的效果最好。学习率和深度学习任务类型有关，合适的学习率往往需要大量的实验和调参经验。探索学习率最优值时需要注意如下两点：\n",
    "\n",
    "- **学习率不是越小越好**。学习率越小，损失函数的变化速度越慢，意味着我们需要花费更长的时间进行收敛，如 **图2** 左图所示。\n",
    "- **学习率不是越大越好**。只根据总样本集中的一个批次计算梯度，抽样误差会导致计算出的梯度不是全局最优的方向，且存在波动。在接近最优解时，过大的学习率会导致参数在最优解附近震荡，损失难以收敛，如 **图2** 右图所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/1e0f066dc9fa4e2bbc942447bdc0578c2ffc6afc15684154ae84bcf31b298d7b\" width=\"500\" hegiht=\"\" ></center>\n",
    "<center><br>图2: 不同学习率（步长过小/过大）的示意图</br></center>\n",
    "<br></br>\n",
    "\n",
    "在训练前，我们往往不清楚一个特定问题设置成怎样的学习率是合理的，因此在训练时可以尝试调小或调大，通过观察Loss下降的情况判断合理的学习率，设置学习率的代码如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #设置不同初始学习率\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.01, parameter_list=model.parameters())\n",
    "    # optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.001, parameter_list=model.parameters())\n",
    "    # optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.1, parameter_list=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 学习率的主流优化算法\n",
    "\n",
    "学习率是优化器的一个参数，调整学习率看似是一件非常麻烦的事情，需要不断的调整步长，观察训练时间和Loss的变化。经过研究员的不断的实验，当前已经形成了四种比较成熟的优化算法：SGD、Momentum、AdaGrad和Adam，效果如 **图3** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/f4cf80f95424411a85ad74998433317e721f56ddb4f64e6f8a28a27b6a1baa6b\" width=\"800\" hegiht=\"\" ></center>\n",
    "<center><br>图3: 不同学习率算法效果示意图</br></center>\n",
    "<br></br>\n",
    "\n",
    "* **[SGD：](https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/optimizer_cn/SGDOptimizer_cn.html#cn-api-fluid-optimizer-sgdoptimizer)** 随机梯度下降算法，每次训练少量数据，抽样偏差导致参数收敛过程中震荡。\n",
    "\n",
    "* **[Momentum：](https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/optimizer_cn/MomentumOptimizer_cn.html#cn-api-fluid-optimizer-momentumoptimizer)** 引入物理“动量”的概念，累积速度，减少震荡，使参数更新的方向更稳定。\n",
    "\n",
    "每个批次的数据含有抽样误差，导致梯度更新的方向波动较大。如果我们引入物理动量的概念，给梯度下降的过程加入一定的“惯性”累积，就可以减少更新路径上的震荡，即每次更新的梯度由“历史多次梯度的累积方向”和“当次梯度”加权相加得到。历史多次梯度的累积方向往往是从全局视角更正确的方向，这与“惯性”的物理概念很像，也是为何其起名为“Momentum”的原因。类似不同品牌和材质的篮球有一定的重量差别，街头篮球队中的投手（擅长中远距离投篮）喜欢稍重篮球的比例较高。一个很重要的原因是，重的篮球惯性大，更不容易受到手势的小幅变形或风吹的影响。\n",
    "\n",
    "* **[AdaGrad：](https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/optimizer_cn/AdagradOptimizer_cn.html#cn-api-fluid-optimizer-adagradoptimizer)** 根据不同参数距离最优解的远近，动态调整学习率。学习率逐渐下降，依据各参数变化大小调整学习率。\n",
    "\n",
    "通过调整学习率的实验可以发现：当某个参数的现值距离最优解较远时（表现为梯度的绝对值较大），我们期望参数更新的步长大一些，以便更快收敛到最优解。当某个参数的现值距离最优解较近时（表现为梯度的绝对值较小），我们期望参数的更新步长小一些，以便更精细的逼近最优解。类似于打高尔夫球，专业运动员第一杆开球时，通常会大力打一个远球，让球尽量落在洞口附近。当第二杆面对离洞口较近的球时，他会更轻柔而细致的推杆，避免将球打飞。与此类似，参数更新的步长应该随着优化过程逐渐减少，减少的程度与当前梯度的大小有关。根据这个思想编写的优化算法称为“AdaGrad”，Ada是Adaptive的缩写，表示“适应环境而变化”的意思。[RMSProp](https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/optimizer_cn/RMSPropOptimizer_cn.html#rmspropoptimizer)是在AdaGrad基础上的改进，AdaGrad会累加之前所有的梯度平方，而RMSprop仅仅是计算对应的梯度平均值，因而可以解决AdaGrad学习率急剧下降的问题。\n",
    "\n",
    "* **[Adam：](https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/optimizer_cn/AdamOptimizer_cn.html#cn-api-fluid-optimizer-adamoptimizer)**  由于动量和自适应学习率两个优化思路是正交的，因此可以将两个思路结合起来，这就是当前广泛应用的算法。\n",
    "\n",
    "\n",
    "------\n",
    "**说明：**\n",
    "\n",
    "每种优化算法均有更多的参数设置，详情可查阅[飞桨的官方API文档](https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/optimizer_cn.html)。理论最合理的未必在具体案例中最有效，所以模型调参是很有必要的，最优的模型配置往往是在一定“理论”和“经验”的指导下实验出来的。\n",
    "\n",
    "------\n",
    "\n",
    "我们可以尝试选择不同的优化算法训练模型，观察训练时间和损失变化的情况，代码实现如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #四种优化算法的设置方案，可以逐一尝试效果\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.01, parameter_list=model.parameters())\n",
    "    #optimizer = fluid.optimizer.MomentumOptimizer(learning_rate=0.01, momentum=0.9, parameter_list=model.parameters())\n",
    "    #optimizer = fluid.optimizer.AdagradOptimizer(learning_rate=0.01, parameter_list=model.parameters())\n",
    "    #optimizer = fluid.optimizer.AdamOptimizer(learning_rate=0.01, parameter_list=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单GPU训练\n",
    "\n",
    "飞桨动态图通过fluid.dygraph.guard(place=None)里的``place``参数，设置在GPU上训练还是CPU上训练。\n",
    "\n",
    "```\n",
    "with fluid.dygraph.guard(place=fluid.CPUPlace())　#设置使用CPU资源训神经网络。\n",
    "with fluid.dygraph.guard(place=fluid.CUDAPlace(0))　#设置使用GPU资源训神经网络，默认使用服务器的第一个GPU卡。\"0\"是GPU卡的编号，比如一台服务器有的四个GPU卡，编号分别为０、１、２、３。\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算模型的分类准确率\n",
    "\n",
    "准确率是一个直观衡量分类模型效果的指标，由于这个指标是离散的，因此不适合作为损失函数来优化。通常情况下，交叉熵损失越小的模型，分类的准确率也越高。基于分类准确率，我们可以公平的比较两种损失函数的优劣，例如[【手写数字识别】之损失函数 ](https://aistudio.baidu.com/aistudio/projectdetail/715334)章节中均方误差和交叉熵的比较。\n",
    "\n",
    "飞桨提供了计算分类准确率的API，使用[fluid.layers.accuracy](https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/layers_cn/accuracy_cn.html#accuracy)可以直接计算准确率，该API的输入参数input为预测的分类结果predict，输入参数label为数据真实的label。\n",
    "\n",
    "在下述代码中，我们在模型前向计算过程forward函数中计算分类准确率，并在训练时打印每个批次样本的分类准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载相关库\n",
    "import os\n",
    "import random\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "# 定义数据集读取器\n",
    "def load_data(mode='train'):\n",
    "\n",
    "    # 读取数据文件\n",
    "    datafile = './work/mnist.json.gz'\n",
    "    print('loading mnist dataset from {} ......'.format(datafile))\n",
    "    data = json.load(gzip.open(datafile))\n",
    "    # 读取数据集中的训练集，验证集和测试集\n",
    "    train_set, val_set, eval_set = data\n",
    "\n",
    "    # 数据集相关参数，图片高度IMG_ROWS, 图片宽度IMG_COLS\n",
    "    IMG_ROWS = 28\n",
    "    IMG_COLS = 28\n",
    "    # 根据输入mode参数决定使用训练集，验证集还是测试\n",
    "    if mode == 'train':\n",
    "        imgs = train_set[0]\n",
    "        labels = train_set[1]\n",
    "    elif mode == 'valid':\n",
    "        imgs = val_set[0]\n",
    "        labels = val_set[1]\n",
    "    elif mode == 'eval':\n",
    "        imgs = eval_set[0]\n",
    "        labels = eval_set[1]\n",
    "    # 获得所有图像的数量\n",
    "    imgs_length = len(imgs)\n",
    "    # 验证图像数量和标签数量是否一致\n",
    "    assert len(imgs) == len(labels), \\\n",
    "          \"length of train_imgs({}) should be the same as train_labels({})\".format(\n",
    "                  len(imgs), len(labels))\n",
    "\n",
    "    index_list = list(range(imgs_length))\n",
    "\n",
    "    # 读入数据时用到的batchsize\n",
    "    BATCHSIZE = 100\n",
    "\n",
    "    # 定义数据生成器\n",
    "    def data_generator():\n",
    "        # 训练模式下，打乱训练数据\n",
    "        if mode == 'train':\n",
    "            random.shuffle(index_list)\n",
    "        imgs_list = []\n",
    "        labels_list = []\n",
    "        # 按照索引读取数据\n",
    "        for i in index_list:\n",
    "            # 读取图像和标签，转换其尺寸和类型\n",
    "            img = np.reshape(imgs[i], [1, IMG_ROWS, IMG_COLS]).astype('float32')\n",
    "            label = np.reshape(labels[i], [1]).astype('int64')\n",
    "            imgs_list.append(img) \n",
    "            labels_list.append(label)\n",
    "            # 如果当前数据缓存达到了batch size，就返回一个批次数据\n",
    "            if len(imgs_list) == BATCHSIZE:\n",
    "                yield np.array(imgs_list), np.array(labels_list)\n",
    "                # 清空数据缓存列表\n",
    "                imgs_list = []\n",
    "                labels_list = []\n",
    "\n",
    "        # 如果剩余数据的数目小于BATCHSIZE，\n",
    "        # 则剩余数据一起构成一个大小为len(imgs_list)的mini-batch\n",
    "        if len(imgs_list) > 0:\n",
    "            yield np.array(imgs_list), np.array(labels_list)\n",
    "\n",
    "    return data_generator\n",
    "\n",
    "\n",
    "# 定义模型结构\n",
    "class MNIST(fluid.dygraph.Layer):\n",
    "     def __init__(self):\n",
    "         super(MNIST, self).__init__()\n",
    "         \n",
    "         # 定义一个卷积层，使用relu激活函数\n",
    "         self.conv1 = Conv2D(num_channels=1, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\n",
    "         # 定义一个池化层，池化核为2，步长为2，使用最大池化方式\n",
    "         self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "         # 定义一个卷积层，使用relu激活函数\n",
    "         self.conv2 = Conv2D(num_channels=20, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\n",
    "         # 定义一个池化层，池化核为2，步长为2，使用最大池化方式\n",
    "         self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "         # 定义一个全连接层，输出节点数为10 \n",
    "         self.fc = Linear(input_dim=980, output_dim=10, act='softmax')\n",
    "    # 定义网络的前向计算过程\n",
    "     def forward(self, inputs, label):\n",
    "         x = self.conv1(inputs)\n",
    "         x = self.pool1(x)\n",
    "         x = self.conv2(x)\n",
    "         x = self.pool2(x)\n",
    "         x = fluid.layers.reshape(x, [x.shape[0], 980])\n",
    "         x = self.fc(x)\n",
    "         if label is not None:\n",
    "             acc = fluid.layers.accuracy(input=x, label=label)\n",
    "             return x, acc\n",
    "         else:\n",
    "             return x\n",
    "\n",
    "#调用加载数据的函数\n",
    "train_loader = load_data('train')\n",
    "    \n",
    "#在使用GPU机器时，可以将use_gpu变量设置成True\n",
    "use_gpu = False\n",
    "place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "\n",
    "with fluid.dygraph.guard(place):\n",
    "    model = MNIST()\n",
    "    model.train() \n",
    "    \n",
    "    #四种优化算法的设置方案，可以逐一尝试效果\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.01, parameter_list=model.parameters())\n",
    "    #optimizer = fluid.optimizer.MomentumOptimizer(learning_rate=0.01, momentum=0.9, parameter_list=model.parameters())\n",
    "    #optimizer = fluid.optimizer.AdagradOptimizer(learning_rate=0.01, parameter_list=model.parameters())\n",
    "    #optimizer = fluid.optimizer.AdamOptimizer(learning_rate=0.01, parameter_list=model.parameters())\n",
    "    \n",
    "    EPOCH_NUM = 5\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据\n",
    "            image_data, label_data = data\n",
    "            image = fluid.dygraph.to_variable(image_data)\n",
    "            label = fluid.dygraph.to_variable(label_data)\n",
    "            \n",
    "            #前向计算的过程，同时拿到模型输出值和分类准确率\n",
    "            predict, acc = model(image, label)\n",
    "            \n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = fluid.layers.cross_entropy(predict, label)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            \n",
    "            #每训练了200批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), acc.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            optimizer.minimize(avg_loss)\n",
    "            model.clear_gradients()\n",
    "\n",
    "    #保存模型参数\n",
    "    fluid.save_dygraph(model.state_dict(), 'mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查模型训练过程，识别潜在训练问题\n",
    "\n",
    "使用飞桨动态图可以方便的查看和调试训练的执行过程。在网络定义的``Forward``函数中，可以打印每一层输入输出的尺寸，以及每层网络的参数。通过查看这些信息，不仅可以更好地理解训练的执行过程，还可以发现潜在问题，或者启发继续优化的思路。\n",
    "\n",
    "在下述程序中，使用``check_shape``变量控制是否打印“尺寸”，验证网络结构是否正确。使用``check_content``变量控制是否打印“内容值”，验证数据分布是否合理。假如在训练中发现中间层的部分输出持续为0，说明该部分的网络结构设计存在问题，没有充分利用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型结构\n",
    "class MNIST(fluid.dygraph.Layer):\n",
    "     def __init__(self):\n",
    "         super(MNIST, self).__init__()\n",
    "         \n",
    "         # 定义一个卷积层，使用relu激活函数\n",
    "         self.conv1 = Conv2D(num_channels=1, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\n",
    "         # 定义一个池化层，池化核为2，步长为2，使用最大池化方式\n",
    "         self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "         # 定义一个卷积层，使用relu激活函数\n",
    "         self.conv2 = Conv2D(num_channels=20, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\n",
    "         # 定义一个池化层，池化核为2，步长为2，使用最大池化方式\n",
    "         self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "         # 定义一个全连接层，输出节点数为10 \n",
    "         self.fc = Linear(input_dim=980, output_dim=10, act='softmax')\n",
    "     \n",
    "     # 加入对每一层输入和输出的尺寸和数据内容的打印，根据check参数决策是否打印每层的参数和输出尺寸\n",
    "     def forward(self, inputs, label=None, check_shape=False, check_content=False):\n",
    "         # 给不同层的输出不同命名，方便调试\n",
    "         outputs1 = self.conv1(inputs)\n",
    "         outputs2 = self.pool1(outputs1)\n",
    "         outputs3 = self.conv2(outputs2)\n",
    "         outputs4 = self.pool2(outputs3)\n",
    "         _outputs4 = fluid.layers.reshape(outputs4, [outputs4.shape[0], -1])\n",
    "         outputs5 = self.fc(_outputs4)\n",
    "         \n",
    "         # 选择是否打印神经网络每层的参数尺寸和输出尺寸，验证网络结构是否设置正确\n",
    "         if check_shape:\n",
    "             # 打印每层网络设置的超参数-卷积核尺寸，卷积步长，卷积padding，池化核尺寸\n",
    "             print(\"\\n########## print network layer's superparams ##############\")\n",
    "             print(\"conv1-- kernel_size:{}, padding:{}, stride:{}\".format(self.conv1.weight.shape, self.conv1._padding, self.conv1._stride))\n",
    "             print(\"conv2-- kernel_size:{}, padding:{}, stride:{}\".format(self.conv2.weight.shape, self.conv2._padding, self.conv2._stride))\n",
    "             print(\"pool1-- pool_type:{}, pool_size:{}, pool_stride:{}\".format(self.pool1._pool_type, self.pool1._pool_size, self.pool1._pool_stride))\n",
    "             print(\"pool2-- pool_type:{}, poo2_size:{}, pool_stride:{}\".format(self.pool2._pool_type, self.pool2._pool_size, self.pool2._pool_stride))\n",
    "             print(\"fc-- weight_size:{}, bias_size_{}, activation:{}\".format(self.fc.weight.shape, self.fc.bias.shape, self.fc._act))\n",
    "             \n",
    "             # 打印每层的输出尺寸\n",
    "             print(\"\\n########## print shape of features of every layer ###############\")\n",
    "             print(\"inputs_shape: {}\".format(inputs.shape))\n",
    "             print(\"outputs1_shape: {}\".format(outputs1.shape))\n",
    "             print(\"outputs2_shape: {}\".format(outputs2.shape))\n",
    "             print(\"outputs3_shape: {}\".format(outputs3.shape))\n",
    "             print(\"outputs4_shape: {}\".format(outputs4.shape))\n",
    "             print(\"outputs5_shape: {}\".format(outputs5.shape))\n",
    "             \n",
    "         # 选择是否打印训练过程中的参数和输出内容，可用于训练过程中的调试\n",
    "         if check_content:\n",
    "            # 打印卷积层的参数-卷积核权重，权重参数较多，此处只打印部分参数\n",
    "             print(\"\\n########## print convolution layer's kernel ###############\")\n",
    "             print(\"conv1 params -- kernel weights:\", self.conv1.weight[0][0])\n",
    "             print(\"conv2 params -- kernel weights:\", self.conv2.weight[0][0])\n",
    "\n",
    "             # 创建随机数，随机打印某一个通道的输出值\n",
    "             idx1 = np.random.randint(0, outputs1.shape[1])\n",
    "             idx2 = np.random.randint(0, outputs3.shape[1])\n",
    "             # 打印卷积-池化后的结果，仅打印batch中第一个图像对应的特征\n",
    "             print(\"\\nThe {}th channel of conv1 layer: \".format(idx1), outputs1[0][idx1])\n",
    "             print(\"The {}th channel of conv2 layer: \".format(idx2), outputs3[0][idx2])\n",
    "             print(\"The output of last layer:\", outputs5[0], '\\n')\n",
    "            \n",
    "        # 如果label不是None，则计算分类精度并返回\n",
    "         if label is not None:\n",
    "             acc = fluid.layers.accuracy(input=outputs5, label=label)\n",
    "             return outputs5, acc\n",
    "         else:\n",
    "             return outputs5\n",
    "\n",
    "    \n",
    "#在使用GPU机器时，可以将use_gpu变量设置成True\n",
    "use_gpu = False\n",
    "place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "\n",
    "with fluid.dygraph.guard(place):\n",
    "    model = MNIST()\n",
    "    model.train() \n",
    "    \n",
    "    #四种优化算法的设置方案，可以逐一尝试效果\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.01, parameter_list=model.parameters())\n",
    "    #optimizer = fluid.optimizer.MomentumOptimizer(learning_rate=0.01, momentum=0.9, parameter_list=model.parameters())\n",
    "    #optimizer = fluid.optimizer.AdagradOptimizer(learning_rate=0.01, parameter_list=model.parameters())\n",
    "    #optimizer = fluid.optimizer.AdamOptimizer(learning_rate=0.01, parameter_list=model.parameters())\n",
    "    \n",
    "    EPOCH_NUM = 1\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据，变得更加简洁\n",
    "            image_data, label_data = data\n",
    "            image = fluid.dygraph.to_variable(image_data)\n",
    "            label = fluid.dygraph.to_variable(label_data)\n",
    "            \n",
    "            #前向计算的过程，同时拿到模型输出值和分类准确率\n",
    "            if batch_id == 0 and epoch_id==0:\n",
    "                # 打印模型参数和每层输出的尺寸\n",
    "                predict, acc = model(image, label, check_shape=True, check_content=False)\n",
    "            elif batch_id==401:\n",
    "                # 打印模型参数和每层输出的值\n",
    "                predict, acc = model(image, label, check_shape=False, check_content=True)\n",
    "            else:\n",
    "                predict, acc = model(image, label)\n",
    "            \n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = fluid.layers.cross_entropy(predict, label)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}, acc is {}\".format(epoch_id, batch_id, avg_loss.numpy(), acc.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            optimizer.minimize(avg_loss)\n",
    "            model.clear_gradients()\n",
    "\n",
    "    #保存模型参数\n",
    "    fluid.save_dygraph(model.state_dict(), 'mnist')\n",
    "    print(\"Model has been saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加入校验或测试，更好评价模型效果 \n",
    "\n",
    "在训练过程中，我们会发现模型在训练样本集上的损失在不断减小。但这是否代表模型在未来的应用场景上依然有效？为了验证模型的有效性，通常将样本集合分成三份，训练集、校验集和测试集。\n",
    "\n",
    "- **训练集** ：用于训练模型的参数，即训练过程中主要完成的工作。\n",
    "- **校验集** ：用于对模型超参数的选择，比如网络结构的调整、正则化项权重的选择等。\n",
    "- **测试集** ：用于模拟模型在应用后的真实效果。因为测试集没有参与任何模型优化或参数训练的工作，所以它对模型来说是完全未知的样本。在不以校验数据优化网络结构或模型超参数时，校验数据和测试数据的效果是类似的，均更真实的反映模型效果。\n",
    "\n",
    "如下程序读取上一步训练保存的模型参数，读取测试数据集，并测试模型在测试数据集上的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fluid.dygraph.guard():\n",
    "    print('start evaluation .......')\n",
    "    #加载模型参数\n",
    "    model = MNIST()\n",
    "    model_state_dict, _ = fluid.load_dygraph('mnist')\n",
    "    model.load_dict(model_state_dict)\n",
    "\n",
    "    model.eval()\n",
    "    eval_loader = load_data('eval')\n",
    "\n",
    "    acc_set = []\n",
    "    avg_loss_set = []\n",
    "    for batch_id, data in enumerate(eval_loader()):\n",
    "        x_data, y_data = data\n",
    "        img = fluid.dygraph.to_variable(x_data)\n",
    "        label = fluid.dygraph.to_variable(y_data)\n",
    "        prediction, acc = model(img, label)\n",
    "        loss = fluid.layers.cross_entropy(input=prediction, label=label)\n",
    "        avg_loss = fluid.layers.mean(loss)\n",
    "        acc_set.append(float(acc.numpy()))\n",
    "        avg_loss_set.append(float(avg_loss.numpy()))\n",
    "    \n",
    "    #计算多个batch的平均损失和准确率\n",
    "    acc_val_mean = np.array(acc_set).mean()\n",
    "    avg_loss_val_mean = np.array(avg_loss_set).mean()\n",
    "\n",
    "    print('loss={}, acc={}'.format(avg_loss_val_mean, acc_val_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加入正则化项，避免模型过拟合\n",
    "   \n",
    "## 过拟合现象\n",
    "\n",
    "对于样本量有限、但需要使用强大模型的复杂任务，模型很容易出现过拟合的表现，即在训练集上的损失小，在验证集或测试集上的损失较大，如 **图2** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/99b879c21113494a9d7315eeda74bc4c8fea07f984824a03bf8411e946c75f1b\" width=\"400\" hegiht=\"\" ></center>\n",
    "<center><br>图2：过拟合现象，训练误差不断降低，但测试误差先降后增</br></center>\n",
    "<br></br>\n",
    "\n",
    "反之，如果模型在训练集和测试集上均损失较大，则称为欠拟合。过拟合表示模型过于敏感，学习到了训练数据中的一些误差，而这些误差并不是真实的泛化规律（可推广到测试集上的规律）。欠拟合表示模型还不够强大，还没有很好的拟合已知的训练样本，更别提测试样本了。因为欠拟合情况容易观察和解决，只要训练loss不够好，就不断使用更强大的模型即可，因此实际中我们更需要处理好过拟合的问题。\n",
    "\n",
    "## 导致过拟合原因\n",
    "\n",
    "造成过拟合的原因是模型过于敏感，而训练数据量太少或其中的噪音太多。\n",
    "\n",
    "如**图3** 所示，理想的回归模型是一条坡度较缓的抛物线，欠拟合的模型只拟合出一条直线，显然没有捕捉到真实的规律，但过拟合的模型拟合出存在很多拐点的抛物线，显然是过于敏感，也没有正确表达真实规律。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/53c389bb3c824706bd2fbc05f83ab0c6dd6b5b2fdedb4150a17e16a1b64c243e\" width=\"700\" hegiht=\"\" ></center>\n",
    "<center><br>图3：回归模型的过拟合，理想和欠拟合状态的表现</br></center>\n",
    "<br></br>\n",
    "\n",
    "如**图4** 所示，理想的分类模型是一条半圆形的曲线，欠拟合用直线作为分类边界，显然没有捕捉到真实的边界，但过拟合的模型拟合出很扭曲的分类边界，虽然对所有的训练数据正确分类，但对一些较为个例的样本所做出的妥协，高概率不是真实的规律。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/b5a46f7e0fbe4f8686a71d9a2d330ed09f23bca565a44e0d941148729fd2f7d7\" width=\"700\" hegiht=\"\" ></center>\n",
    "<center><br>图4：分类模型的欠拟合，理想和过拟合状态的表现</br></center>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过拟合的成因与防控\n",
    "\n",
    "为了更好的理解过拟合的成因，可以参考侦探定位罪犯的案例逻辑，如 **图5** 所示。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/34de60a675b64468a2c3fee0844a168d53e891eaacf643fd8c1c9ba8e3812bcc\" width=\"700\" hegiht=\"\" ></center>\n",
    "<center><br>图5：侦探定位罪犯与模型假设示意</br></center>\n",
    "<br></br>\n",
    "\n",
    "**对于这个案例，假设侦探也会犯错，通过分析发现可能的原因：**\n",
    "\n",
    "1. 情况1：罪犯证据存在错误，依据错误的证据寻找罪犯肯定是缘木求鱼。\n",
    "\n",
    "2. 情况2：搜索范围太大的同时证据太少，导致符合条件的候选（嫌疑人）太多，无法准确定位罪犯。\n",
    "\n",
    "**那么侦探解决这个问题的方法有两种：或者缩小搜索范围（比如假设该案件只能是熟人作案），或者寻找更多的证据。**\n",
    "\n",
    "**归结到深度学习中，假设模型也会犯错，通过分析发现可能的原因：**\n",
    "\n",
    "1. 情况1：训练数据存在噪音，导致模型学到了噪音，而不是真实规律。\n",
    "\n",
    "2. 情况2：使用强大模型（表示空间大）的同时训练数据太少，导致在训练数据上表现良好的候选假设太多，锁定了一个“虚假正确”的假设。\n",
    "\n",
    "**对于情况1，我们使用数据清洗和修正来解决。 对于情况2，我们或者限制模型表示能力，或者收集更多的训练数据。**\n",
    "\n",
    "而清洗训练数据中的错误，或收集更多的训练数据往往是一句“正确的废话”，在任何时候我们都想获得更多更高质量的数据。在实际项目中，更快、更低成本可控制过拟合的方法，只有限制模型的表示能力。\n",
    "\n",
    "## 正则化项\n",
    "\n",
    "为了防止模型过拟合，在没有扩充样本量的可能下，只能降低模型的复杂度，可以通过限制参数的数量或可能取值（参数值尽量小）实现。\n",
    "\n",
    "具体来说，在模型的优化目标（损失）中人为加入对参数规模的惩罚项。当参数越多或取值越大时，该惩罚项就越大。通过调整惩罚项的权重系数，可以使模型在“尽量减少训练损失”和“保持模型的泛化能力”之间取得平衡。泛化能力表示模型在没有见过的样本上依然有效。正则化项的存在，增加了模型在训练集上的损失。\n",
    "\n",
    "飞桨支持为所有参数加上统一的正则化项，也支持为特定的参数添加正则化项。前者的实现如下代码所示，仅在优化器中设置``regularization``参数即可实现。使用参数``regularization_coeff``调节正则化项的权重，权重越大时，对模型复杂度的惩罚越高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各种优化算法均可以加入正则化项，避免过拟合，参数regularization_coeff调节正则化项的权重\n",
    "    #optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.01, regularization=fluid.regularizer.L2Decay(regularization_coeff=0.1),parameter_list=model.parameters()))\n",
    "    optimizer = fluid.optimizer.AdamOptimizer(learning_rate=0.01, regularization=fluid.regularizer.L2Decay(regularization_coeff=0.1),parameter_list=model.parameters())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
